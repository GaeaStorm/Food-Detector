{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd48223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visible devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Visible devices:\", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71593af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(split_dir, img_size=(224, 224), batch_size=8, shuffle=True):\n",
    "    split_dir = Path(split_dir)\n",
    "    csv_path = split_dir / \"_classes.csv\"\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    filepaths = df[\"filename\"].apply(lambda fname: str(split_dir / fname)).values\n",
    "    labels = df.drop(columns=[\"filename\"]).values.astype(\"float32\")\n",
    "    num_classes = labels.shape[1]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(512, len(filepaths)))  # 512 is plenty\n",
    "\n",
    "    def load_image(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, img_size)        # ğŸ‘ˆ resize here!\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img, label\n",
    "\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9af45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, num_classes = make_dataset(\"dataset/train\", batch_size=8, shuffle=True)\n",
    "valid_ds, _          = make_dataset(\"dataset/valid\", batch_size=8, shuffle=False)\n",
    "test_ds, _           = make_dataset(\"dataset/test\",  batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "debdf904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images: (8, 224, 224, 3)\n",
      "Batch labels: (8, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 00:11:02.383767: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch_images, batch_labels in train_ds.take(1):\n",
    "    print(\"Batch images:\", batch_images.shape)\n",
    "    print(\"Batch labels:\", batch_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "881bbe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "INPUT_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    pooling=\"avg\",  # gives a 2048-d feature vector\n",
    ")\n",
    "\n",
    "# First: freeze the base model (only train new head)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
    "# x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
    "x = inputs\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "# x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# Multi-label output â†’ sigmoid\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6c71b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HammingLoss(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"hamming_loss\", threshold=0.5, **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.total_loss = self.add_weight(name=\"total_loss\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert probabilities â†’ 0/1 labels\n",
    "        y_pred_bin = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "        # Compare predictions vs labels\n",
    "        mismatches = tf.not_equal(y_true, y_pred_bin)\n",
    "        mismatches = tf.cast(mismatches, tf.float32)\n",
    "\n",
    "        # Hamming loss per sample: mean mismatches across classes\n",
    "        sample_loss = tf.reduce_mean(mismatches, axis=1)\n",
    "\n",
    "        # Accumulate\n",
    "        self.total_loss.assign_add(tf.reduce_sum(sample_loss))\n",
    "        self.count.assign_add(tf.cast(tf.size(sample_loss), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total_loss / self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.total_loss.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "\n",
    "class MultiLabelAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"multilabel_accuracy\", threshold=0.5, **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.total_acc = self.add_weight(name=\"total_acc\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Turn predictions into binary decisions\n",
    "        y_pred_bin = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "        # Label-wise correctness: shape (batch, num_labels)\n",
    "        matches = tf.cast(tf.equal(y_true, y_pred_bin), tf.float32)\n",
    "\n",
    "        # Per-sample accuracy: shape (batch,)\n",
    "        sample_acc = tf.reduce_mean(matches, axis=1)\n",
    "\n",
    "        # Accumulate\n",
    "        self.total_acc.assign_add(tf.reduce_sum(sample_acc))\n",
    "        self.count.assign_add(tf.cast(tf.shape(sample_acc)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total_acc / self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.total_acc.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "148b8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        HammingLoss(),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        MultiLabelAccuracy(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "967bd39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - auc: 0.7313 - hamming_loss: 0.3051 - loss: 0.5549 - multilabel_accuracy: 0.6949 - val_auc: 0.7803 - val_hamming_loss: 0.2663 - val_loss: 0.5039 - val_multilabel_accuracy: 0.7337\n",
      "Epoch 2/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - auc: 0.7578 - hamming_loss: 0.2894 - loss: 0.5280 - multilabel_accuracy: 0.7106 - val_auc: 0.7780 - val_hamming_loss: 0.2717 - val_loss: 0.5024 - val_multilabel_accuracy: 0.7283\n",
      "Epoch 3/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - auc: 0.7628 - hamming_loss: 0.2864 - loss: 0.5220 - multilabel_accuracy: 0.7136 - val_auc: 0.7778 - val_hamming_loss: 0.2663 - val_loss: 0.5013 - val_multilabel_accuracy: 0.7337\n",
      "Epoch 4/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - auc: 0.7651 - hamming_loss: 0.2847 - loss: 0.5189 - multilabel_accuracy: 0.7153 - val_auc: 0.7785 - val_hamming_loss: 0.2663 - val_loss: 0.5010 - val_multilabel_accuracy: 0.7337\n",
      "Epoch 5/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - auc: 0.7653 - hamming_loss: 0.2823 - loss: 0.5183 - multilabel_accuracy: 0.7177 - val_auc: 0.7788 - val_hamming_loss: 0.2663 - val_loss: 0.5008 - val_multilabel_accuracy: 0.7337\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=5,        # start small, just to get the head in a good place\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ec59812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 111ms/step - auc: 0.7543 - hamming_loss: 0.2898 - loss: 0.5274 - multilabel_accuracy: 0.7102 - val_auc: 0.7783 - val_hamming_loss: 0.2663 - val_loss: 0.5020 - val_multilabel_accuracy: 0.7337\n",
      "Epoch 2/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - auc: 0.7643 - hamming_loss: 0.2842 - loss: 0.5205 - multilabel_accuracy: 0.7158 - val_auc: 0.7805 - val_hamming_loss: 0.2663 - val_loss: 0.4997 - val_multilabel_accuracy: 0.7337\n",
      "Epoch 3/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - auc: 0.7638 - hamming_loss: 0.2843 - loss: 0.5203 - multilabel_accuracy: 0.7157 - val_auc: 0.7770 - val_hamming_loss: 0.2663 - val_loss: 0.5009 - val_multilabel_accuracy: 0.7337\n",
      "Epoch 4/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 96ms/step - auc: 0.7629 - hamming_loss: 0.2873 - loss: 0.5207 - multilabel_accuracy: 0.7127 - val_auc: 0.7809 - val_hamming_loss: 0.2657 - val_loss: 0.4996 - val_multilabel_accuracy: 0.7343\n",
      "Epoch 5/5\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - auc: 0.7608 - hamming_loss: 0.2885 - loss: 0.5228 - multilabel_accuracy: 0.7115 - val_auc: 0.7791 - val_hamming_loss: 0.2663 - val_loss: 0.5003 - val_multilabel_accuracy: 0.7337\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Option 1: freeze most layers, only train last ~30\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Use a lower LR for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        HammingLoss(),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        MultiLabelAccuracy(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=5,   # or more if itâ€™s stable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095cfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
